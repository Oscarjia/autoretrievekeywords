#### SIF 模型建立

根据processtype类型来判断是按照句子来划分，还是把一篇文章看成一个句子来计算句子向量。

```python
# 2.1 SIF sentence vector 参考链接https://towardsdatascience.com/fse-2b1ffa791cf9
import numpy as np
REAL = np.float32 
from sklearn.decomposition import TruncatedSVD
from sklearn.decomposition import PCA
import jieba
original_dict=dict()
def sif_vectors(sentence_words,processtype,model,alpha=1e-3):
    """Compute the SIF embeddings for a list of sentences
    Parameters
    ----------
    sentences : list
        The sentences to compute the embeddings for
    model : `~gensim.models.base_any2vec.BaseAny2VecModel`
        A gensim model that contains the word vectors and the vocabulary
    alpha : float, optional
        Parameter which is used to weigh each individual word based on its probability p(w).
    Returns
    -------
    numpy.ndarray 
        SIF sentence embedding matrix of dim len(sentences) * dimension
    """
    dicresults=dict()
    output = []
    regex_str1=r"['\n']"
    regex_str2=r"[（ ）▌◆★.@()\-\|!'&?$【】\"\”\“\■\◎\●\/\…\　 　 \\n\:\·]"
    content_line=re.sub(regex_str1,"",sentence_words)
    print("content_line",content_line)
    if processtype=="contents":
        contentlist=content_line.split("。")
    else:
        contentlist=content_line.split("1212125$")
    #contents vector
    for s in contentlist:
        
        if not s:continue
        #print("sentence",s)
        count = 0
        s=re.sub(regex_str2,"",s)
        print("s is:",s)
        v = np.zeros(size, dtype=REAL) # Summary vector
        for w in list(jieba.cut(s,cut_all=False)):
            print("words:",w)
            if w in vlookup:
                v += ( alpha / (alpha + (vlookup[w].count / Z))) * vectors[w]
                count += 1
        if count > 0:
            v *= 1/count
        output.append(v)
    results=np.vstack(output).astype(REAL)
    #SVD
    tsvd = TruncatedSVD(n_components=1, n_iter=7, random_state=0)
    tsvd.fit(results)
    u = tsvd.components_[0]
    u = np.multiply(u, u.T)
    j=0
    for vs in results:
        vs -= np.multiply(u, vs)
    for ss,vec in zip(contentlist,results):
        dicresults[ss]=vec
    return dicresults
    ```
